
%% Adaptado de
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% Traduzido para o congresso de IC da USP
%%*****************************************************************************
% Não modificar

\documentclass[twoside,conference,a4paper]{IEEEtran}

%******************************************************************************
% Não modificar
\usepackage{IEEEtsup} % Definições complementares e modificações.
\usepackage[utf8]{inputenc} % Disponibiliza acentos.
\usepackage[english,brazilian]{babel}
%% Disponibiliza Inglês e Português do Brasil.
\usepackage{latexsym,amsfonts,amssymb} % Disponibiliza fontes adicionais.
\usepackage{theorem}
\usepackage[cmex10]{amsmath} % Pacote matemático básico
\usepackage{url}
%\usepackage[portuges,brazil,english]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{float}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\usepackage[tight,footnotesize]{subfigure}
\usepackage[noadjust]{cite} % Disponibiliza melhorias em citações.
%%*****************************************************************************

\begin{document}
\selectlanguage{brazilian}
\renewcommand{\IEEEkeywordsname}{Palavras-chave}

%%*****************************************************************************

\urlstyle{tt}
% Indicar o nome do autor e o curso/nível (grad-mestrado-doutorado-especial)
\title{Técnicas de Inteligência Artificial para fazer robo NAO aprender a andar}
\author{%
 \IEEEauthorblockN{Jucélio Fonseca\IEEEauthorrefmark{1}, Lucas Padilha\IEEEauthorrefmark{1}, Luciano Sabença\IEEEauthorrefmark{1}, Tomás Silva Queiroga\IEEEauthorrefmark{1}}
 \IEEEauthorblockA{\IEEEauthorrefmark{1}%
                   Ciência da Computação - Graduação}
}

%%*****************************************************************************

\maketitle

%%*****************************************************************************
% Resumo do trabalho
\begin{abstract}
O objetivo deste trabalho é mostrar diferentes abordagens de inteligência articial (IA) para fazer um robo bípede (NAO) andar utilizando o simulador VREP. Fez-se uso de redes neurais artificiais (RNA), aprendizado por reforço e algortimo genéticos. Estudaremos os prós e contras de cada técnica, e exibr dos resultados obtidos.
\end{abstract}

% Indique três palavras-chave que descrevem o trabalho
\begin{IEEEkeywords}
 Robótica, NAO, VREP, aprendizado por reforço, aprendizado supervisionado, algoritmo genético
\end{IEEEkeywords}

%%*****************************************************************************
% Modifique as seções de acordo com o seu projeto

\section{Introdução}

Uma das coisas mais excepcionais da natureza é a capacidade de andar com somente dois apoios. A dificuldade desse método é tão alta que pouquissímos animais conseguiram evoluir para atingir isso, sendo o ser-humano, obviamente, um bom exemplo de tal habilidade. Apesar da dificuldade, há diversas vantagens nesse tipo de movimento, como, por exemplo, a economia de energia, a capacidade de atingir distâncias maiores, além de, no caso dos humanos, amplicar a capacidade de visão.

Em robótica, há muito deseja-se conseguir que robôs bipedes andem de forma autônoma, eficiente e resiliente. Porém o desafio é imenso e ainda não foi totalmente resolvido. Sendo assim, estudaremos este campo buscando fugir das abordagens tradicionais, baseadas em modelos precisos e métodos matemáticos e físicos, para explorar a métodos baseados em inteligência artificial (IA).
Neste trabalho, desenvolvemos diferentes modelos e implementações para o problema de locomoção bípede num robô NAO (Figura \ref{fig:fig1}).  Para testar, usaremos o simulador de robótica \textsl{VREP}, disponibilizado pela empresa Coppelia Robotics GmbH.

\begin{figure}[H]
 \centering
 \includegraphics[scale=1]{figuras/{NAO}.png}
 \caption{Exemplo robô NAO utilizado neste trabalho, um modelo humanóide da empresa francesa Aldebaran extremamente complexo, com 26 graus-de-liberdade (juntas) e diversos tipos de sensores (Fonte: http://goo.gl/MISvjy)}
 \label{fig:fig1}
\end{figure}

O resto do trabalho está dividido da seguinte maneira: na seção \ref{dificuldades} trataremos das dificuldades do problema de locomoção bípede, mostraremos as soluções e modelos normalmente adotados para resolvê-lo e também mostraremos brevemente o estado-da-arte para o robô NAO.

 Na seção \ref{aprendizagem_supervisionada} trataremos do modelo que implementamos baseado em aprendizagem supervisionada e redes-neurais artificiais, mostraremos os resultados e evolução ao longo do tempo, além de também destacar os problemas e limitações dessa abordagem. Na seção \ref{aprendizagem_por_reforco}, mostraremos o modelo que montamos usando a técnica de aprendizagem por reforço, seus resultados e dificuldades. Faremos o mesmo das seções anteriores para a seção \ref{algoritmos_geneticos}. Por fim, daremos um panôrama do problema e dos modelos que usamos nesse trabalho, também discutiremos os resultados que obtemos e propôremos soluções para trabalhos futuros nesse tema na seção \ref{conclusoes}.

\section{Dificuldades do Problema} \label{dificuldades}
A habilidade de caminhar é algo tão automático para seres humanos quanto complexo. Sob um primeiro olhar, pode parecer simplesmente um movimento de pernas coordenados, porém, ao observar mais minunsiosamente, percebe-se que vai muito além disso, até porque, apenas para realizar tal movimento de pernas precisa-se fazer uso do quadril, joelho, tornozelo e pés, rotacionando-os cada um em uma maneira específica em mais de um eixo. Nota-se também que para caminhadas mais rápidas, é necessário também mexer a coluna, ombros, cotovelos, pulso, etc. e que para qualquer caminhada, utilizar de tais partes também é fundamental para manter o equilíbrio, mesmo que suavemente.

O problema de andar então trata-se de realizar uma combinação em função do tempo de qual ângulo qual parte deve assumir para que seja possível sair do lugar. Enumerando rapidamente, observa-se que necessita-se saber, para cada intervalo de tempo, o ângulo do pé, tornozelo, joelho, quadril, coluna, ombros, cotovelo, pulsos, pescoço, ao longo do eixo x, y e z, totalizando em 48 incógnitas que se influenciam. É óbvio então que trata-se de um sistema complexo, sem soluções triviais, que por sua vez é estudado há vários anos.

Uma das abordagens analíticas mais comuns de se resolver o sistema é considerando o centro de massa do ser bípede que se deseja fazer andar. Neste modelo, o centro de massa deve permanecer sempre próximo do seu estado original, variando apenas, claro, ao longo do eixo em que se deseja caminhar através. De maneira simplificada, essa forma de tratar o problema se assemelha ao problema de controlar um pêndulo invertido acoplado a um objeto móvel perpenticular a sua trajetória.

Ponto de momento zero (ZMP - Zero Moment Point) é um dos métodos utilizados para resolver o problema considerando o centro de massa. Ele consiste, basicamente, em encontrar o ponto em que o movimento gera momento horizontal zero no centro de massa, ou seja, um equilíbrio, uma estabilidade dinâmica, visto que caminhar uma órbita periódica com uma fase estável alternada com um instável.

Não importa qual for a abordagem utilizando modelos matemáticos e física, até o momento todas elas tem algo nível de complexidade de resolução e computação, e muitas vezes as soluções tem difícil adaptação para outros robôs. Está é uma das maiores motivações de utilizar técnicas de IA, pois nós, seres humanos, não precisamos de todos estes conhecimentos, obviamente, para conseguir andar. Pode-se dizer que nós aprendemos a caminhar por conta de nossa evolução, por aprendizado por reforço quando pequenos, e com nossas redes neurais, então vamos explorar as abordagens de IA relacionadas a isso individualmente buscando simplificar este processo de ter de descobrir e resolver inúmeras equações complexas.

\section{Aprendizagem Supervisionada} \label{aprendizagem_supervisionada}

Uma das técnicas clássicas da IA, especialmente a parte da IA voltada a \textsl{Machine learning}, é a técnica de aprendizagem supervisionada. Nela, dado um conjunto de entradas e as respectivas saídas esperadas, busca-se inferir a função que gerou esses dados para, dado uma entrada desconhecida, poder ter uma estimativa do valor de saida.

Existem diversos métodos para aprendizagem supervisionada, como por exemplo: árvores de decisões, árvores de regressões, florestas aleatórias, métodos de regressão, redes neurais, etc... Entre todos esses métodos, decidimos aplicar ao problema o método de redes neurais. O fato desse método buscar simular o funcionamento do cérebro e também por ser um bom mecanismo para aproximar funções não-lineares foram os principais motivos que nos levaram a o escolher.

Fizemos uma análise detalhada para tentar entender melhor quais os dados de entrada relevantes para usarmos no treinamento de nossa rede neural. Como o movimento do robô é dependente do movimento de suas juntas e, além disso, o movimento das juntas é absoluto, ou seja, quando enviamos o comando de movimento passamos um ângulo absoluto e não um ângulo relativo à posição atual, descobrimos que o movimento inteiro do robô e, consequentemente, o movimento de andar é totalmente determinado pela mudança de posição das juntas. Sendo assim, foi natural escolhermos a posição das juntas como dado de entrada e consequentemente de treinamento da nossa solução, obtendo como saída a proxima posição das juntas. Restava, obviamente, obté-los.

\subsection{Obtenção do conjunto de treinamento}

Decidimos então usar o \textsl{framework} disponibilizado pelo fabricante para isso. O \textsl{framework}, chamado \textsl{NAOqi}\cite{naoqi} possui diversos métodos de alto-nível para obter diversos tipos de dados, como a leitura de sensores e de juntas, além de implementar diversos tipos de movimento, incluindo um algoritmo para caminhada. Há, porém, um pequeno inconveniente nessa história: o framework, nativamente, não integra com o VREP. Para simular um robô virtual, o fabricante disponibiliza seu próprio simulador, chamado \textsl{Choreography}.

Com as ferramentas instaladas, conseguimos fazer um \textsl{script} que enviava o comando de andar (\textsl{moveToward}) e em seguida fazia leitura das posições das juntas, salvando esses dados num arquivo texto, cujo formato possui 27 campos: o primeiro é o número da movimentação atual e os outros 26 campos as posições de cada uma das juntas. Vale a pena destacar uma dificuldade que tivemos e que para superá-la fizemos alguns testes até obter algo empírico: a diferença de tempo entre as leituras das posições das juntas. O movimento do robô, apesar de ser discreto, aparente ser contínuo, ou seja, não sabemos exatamente qual o período entre os comandos que o SDK envia para o robô. Uma leitura com um intervalo curto poluiria os casos de testes, enxendo-o de inconsistências, pois iriamos ler duas vezes a mesma posição. Por outro lado, um intervalo muito entre as leituras também resultaria em problemas, poderiamos perder movimentações úteis, inclusive algumas que servem para estabilizar a posição do robô. Após diversos testes, usando os dados obtidos no simulador VREP, chegamos à conclusão que o intervalo de tempo adequado seria de 100ms.

\subsection{Treinamento da Rede Neural}

Buscamos bibliotecas que implementam redes neurais em \textsl{Python} e, após várias análises, resolvemos usar uma chamada \textsl{PyBrain}\cite{pybrain}. A biblioteca implementa diversas soluções para \textsl{Machine Learning}, especialmente Redes Neurais, apesar de simples e fácil de usar, ela é bastante poderosa e possui a flexibilidade que precisávamos.

Para análisar a viabilidade da solução, decidimos testar usando um conjunto baixo de épocas, com diferentes topologias de redes e medimos sempre o erro da rede. Começamos com uma topologia simples, com 27 entradas e 26 saídas e somente uma camada ``escondida'' para um conjunto de $2999$ dados e com o tempo fomos aumentando o número de camadas escondidas e o número de épocas e também a taxa de aprendizado. Os dados estão na tabela, \ref{redes_neurais_tabela_1}.


 \begin{table}[h]
 \caption{Dados redes neurais com 27 entradas (indice do movimento + 26 posições de juntas) para \textsl{dataset} completo (2999 entradas)}
 \label{redes_neurais_tabela_1}
 \begin{center}
 \begin{tabular}{|c|c|c|c|}
 \hline
 Hidden Layers & Épocas & Tx de Aprendizado & Erro Quadrático (rmse) \\
 \hline
 1 & 10 & 0.01 & 0.0633488217974 \\
 1 & 30 & 0.01 & 0.0631906312484 \\
 1 & 50 & 0.01 & 0.0630223642902 \\
 1 & 10 & 0.3 & 0.0681891457866 \\
 1 & 30 & 0.3 & 0.0681891457866 \\
 1 & 50 & 0.3 & 0.0751383776067 \\
 3 & 10 &  0.01 & 0.0685694228658 \\
 3 &  30 & 0.01 & 0.061680920708 \\
 3 &  50 & 0.01 & 0.0615565466895 \\
 3 & 10 &  0.3 & 0.0677143739359 \\
 3 &  30 & 0.3 & 0.0984599888321 \\
 3 &  50 & 0.3 & 0.0674333208528 \\
 10 & 10 & 0.01 & 0.0617358134151\\
10 &  30 & 0.01 &  0.0617358134151\\
10 &  50 & 0.01 & 0.0610717443019 \\
10 & 10 & 0.3  & 0.102691352216 \\
10 &  30 & 0.3 & 0.0675102050316 \\
10 &  50 & 0.3 & 0.0972996542286 \\
 \hline
 \end{tabular}
 \end{center}
 \end{table}

 O resultado, conforme pode ser visto na tabela, foi bem aquém do esperado. A taxa de erro quadrática foi alta e não havia sinal de que ia convergir sem muito tempo de treinamento.

Decidimos simplificar a entrada: em vez de incluirmos o número do movimento, usaríamos somente a posição das juntas como entrada. Nossa idéia inicial ao incluir o número do movimento era ajudar o robô a ter um parâmetro a mais para decidir e, além disso, o movimento de andar é um movimento ciclíco, então imaginamos que a rede seria capaz de observar um padrão interessante dessa entrada. Porém, como os dados da tabela \ref{redes_neurais_tabela_2} mostram, nos equivocamos nisso: essa entrada não só não ajudou em nada, como prejudicou a convergência da rede neural.

 \begin{table}[h]
\caption{Dados redes neurais com 26 entradas (as 26 posições de juntas) para \textsl{dataset} completo (2999 entradas)}
 \label{redes_neurais_tabela_2}
 \begin{center}
 \begin{tabular}{|c|c|c|c|}
 \hline
 Hidden Layers & Épocas & Tx de Aprendizado & Erro Quadrático (rmse) \\
 \hline
 1 & 10 & 0.01 & 0.0636479207235 \\
 1 & 30 & 0.01 & 0.0614250925212 \\
 1 & 50 & 0.01 & 0.0536616360962 \\
 1 & 10 & 0.3 & 0.0619223322253 \\
 1 & 30 & 0.3 & 0.0534621202117 \\
 1 & 50 & 0.3 & 0.0533666052268 \\
 3 & 10 &  0.01 & 0.0622194830427\\
 3 &  30 & 0.01 & 0.053521956846 \\
 3 &  50 & 0.01 & 0.0311919046022\\
 3 & 10 &  0.3 & 0.0337463692068 \\
 3 &  30 & 0.3 & 0.0302587699045 \\
 3 &  50 & 0.3 &  0.0328621219436\\
 10 & 10 & 0.01 &  0.0552839022201 \\
10 &  30 & 0.01 & 0.0310246666045 \\
10 &  50 & 0.01 & 0.0323538519379 \\
10 & 10 & 0.3  &  0.0201064129557 \\
10 &  30 & 0.3 & 0.0301485132897 \\
10 &  50 & 0.3 & 0.0162431820288 \\
 \hline
 \end{tabular}
 \end{center}
 \end{table}

Com esses dados em mão, decidimos dar uma boa quantidade de épocas para o treinamento, treinar com um segundo \textsl{dataset} menor  - com 500 entradas - e fixar a rede neural em 3  camadas escondidas para o \textsl{dataset} menor e em 10 para o \textsl{dataset} maior. Por último, fixamos a taxa de aprendizado em $0.3$ para ambos os \textsl{datasets}. Conforme os dados mostram \ref{redes_neurais_tabela_3}, obtivemos melhores resultados de convergência.

 \begin{table}[h]
\caption{Redes Neurais ótimas obtidas por treinamento longo}
 \label{redes_neurais_tabela_3}
 \begin{center}
 \begin{tabular}{|c|c|c|c|c|}
 \hline
 $I$ & \# Dataset & Hidden Layers & Épocas & Erro Quadrático (rmse) \\
 \hline
 1 & 500  & 3 & 600 & 0.0272638446791 \\
 2 & 2999 & 10 & 600 & 0.00887537932562 \\
 \hline
 \end{tabular}
 \end{center}
 \end{table}

Com todas essas reudes neurais treinadas e prontas para serem usadas, decidimos testar as mais promissoras delas, que no caso, foram as que foram treinadas por mais tempo, apresentadas na \ref{redes_neurais_tabela_3}, além de darmos uma chance para a melhor das redes neurais da tabela \ref{redes_neurais_tabela_1}. Por comodidade, também vamos eventualmente nos referir às redes da tabela \ref{redes_neurais_tabela_3} pelo número da coluna $I$.

\subsection{Aplicando as Redes Neurais no Robô}

Para aplicar a rede neural no robô fizemos uma função que lê a posição de todas as juntas no VREP e na ordem que usamos de treinamento. Essa função é utilizada num \textsl{loop} que lê a posição das juntas, usá-as como entrada da rede, obtém a saída e envia o comando de para as juntas irem nas posições de saida.

Como era de se esperar olhando a convergência da rede, quando aplicamos a melhor rede neural  da tabela \ref{redes_neurais_tabela_1} obtivemos um resultado ruim, o robô simplemente desequilibrou.

Tentamos então utilizar a rede neural treinada por 600 épocas com o \textsl{dataset} de $2999$. O resultado também não foi bom. O robô tentava dar o primeiro passo e sair da posição inicial, porém se desequilibrava e caía. Há, contudo, uma observação interessante a ser feita: mesmo no chão o robô movia as pernas num movimento semelhante a andar, como é possível ver na sequência de imagens %TODO%.

%TODO colocar imagens.


Por último, testamos a rede neural treinada com $500$ exemplos de movimentação. Essa rede neural foi a mais promissora até o momento: o robô conseguiu sair da posição inicial, ficar em equilibrío e chegar perto de dar os primeiros passos. Porém após alguns movimentos o robô simplesmente ficava parado numa posição similar ao momento de impulso para o proximo passo, conforme mostram as figuras %TODO %.

%TODO colocar imagens.

Ao obsevarmos os comportamentos decidimos testar uma abordagem mista, ou seja, fazer os primeiros movimentos do robô com a rede neural treinada com menos exemplos e depois continuar os movimentos usando a segunda rede neural testada. O resultado disso foi que, finalmente, conseguimos replicar, ainda que de forma não tão precisa, os movimentos de andar que a biblioteca do NAOqi implementa. Esses movimentos podem ser vistos na figura %TODO %.

\subsection{Interpretação dos Testes e dos Resultados Obtidos}

Nossos testes reforçaram a dificuldade esmiúçadas na seção \ref{dificuldades}. Para a abordagem de aprendizado supervisionado, a maior dificuldade foi o robô fazer os movimentos de andar mantendo o equilíbrio. O fato de uma rede neural ter a capacidade de aprender funções complexas, incluindo as não-lineares - como é o caso -  fez com que essa solução funcionasse.

Contudo, foi uma surpresa para nós as condições para as quais isso funcionou ou, equivalentemente, o comportamento que observamos quando combinamos as duas melhores redes neurais. Essa supresa se deve principalmente em relação ao comportamento que observamos quando testamos as redes isoladamente. Ficamos instigados a descobrir o motivo disso. Infelizmente, uma das características de redes neurais quando comparadas com outros método, como a árvore de decisão, é que é muito dificil prever totalmente o estado que a rede ficará, sendo assim só conseguimos pensar em suposições.

Virou consenso entre nós que o principal motivo desse comportamento se deve a caractéristica ciclica do movimento de andar. Há um certo compasso que se repete a cada passo e, na nossa, visão foi esse compasso que a rede neural aprendeu, porém, devido à quantidade de exemplos dados para o movimento de andar no caso do \textsl{dataset} maior, ela aprendeu esse padrão às custas de desaprender o movimento de sair da posição inicial e buscar estabilidade antes de dar o primeiro passo. Quando treinamos uma rede neural similar com um \textsl{dataset} menor, essa segunda rede aprendeu a sequencia de movimentos para andar de forma incompleta, contudo isso possibilitou que o movimento inicial para ganhar estabilidade e se preparar para andar fosse aprendido e não sobreescrito pelo padrão de movimento usado para caminhar.

Tentamos melhorar o resultado treinando a rede neural 2 com um \textsl{dataset} menor, com somente os movimentos iniciais. Fizemos isso por 100 épocas, porém não conseguimos melhorar o erro da rede. Esse resultado mostra que a rede está bem encaixada para o problema, sendo díficil mexer nos seus pesos sem prejudicar o valor do erro. Para trabalhos futuros sugerimos um estudo mais a fundo da possibilidade de retreinar a rede com esse dataset limitado, provavelmente adicionando um distúrbio nela ou um mecanismo de \textsl{weight decay}\cite{hastie01statisticallearning}.


\section{Aprendizagem Por Reforço} \label{aprendizagem_por_reforco}

Pode-se dizer que crianças fazem uso de aprendizagem por reforço quando estão desenvolvendo suas atividades motoras. Uma época da vida do ser humano em que ele não sabe exatamente o que busca, porém já consegue distinguir o que é melhor ou não de se fazer para se alcançar um objetivo muitas vezes, e com inúmeras tentativas, erros e acertos consegue. Exploramos este conceito utilizando o framework em python FRAMEWORKPYTHON para modelar tal problema, e verificar se esta técnica é eficaz ou não.

O primeiro desafio encontrado para utilizar esta abordagem foi modelar o problema em termos de aprendizagem por reforço. Como temos muitas variáveis (26 articulações que devem se movimentar para fazê-lo andar), cada qual podendo assumir valores contínuos em intervalos diferentes, faz-se necessário simplificar o problema. Então a maneira que modelamos foi COLOCARCOMOMODELAMOS.

Quanto ao que devemos considerar como bom ou ruim para reforçar ou não é mais fácil de se imaginar, então adotamos que quando o robô consegue OQUEELECONSEGUE obtem um REFORCO. Dessa forma, estamos reforçando bons comportamentos do robô no que se diz respeito a conseguir caminhar.

\section{Algoritmos Genéticos} \label{algoritmos_geneticos}

Dada a proximidade que os algoritmos genéticos buscam ter com a natureza, e que os seres humanos são frutos de inúmeras evoluções de populações distintas de animais, parece natural avançar no problema de andar utilizando esta técnica da inteligência artificial. Nela buscamos encontrar, depois de várias gerações, um robô capaz de andar, sem cair, indeterminadamente.

Para isso acontecer, antes de definir tamanho ideal para população, taxa de mutação, pontos de crossover, é necessário formular uma boa função fitness, e codificar um bom cromossomo.

Cada indivíduo (cromossomo) da população é um vetor com $(2N+2)J$ posições, onde $J$ é o número de juntas em que queremos otimizar suas rotações em função do tempo, o número $(2N+2)$ se dá por ser o número de constantes estipuladas em cada função de rotação em função do tempo, e $N$ o número de termos da função $f(t) = \frac{a_0}{2}+\sum_{i=0}^N a_{2i+2} cos(a_{1} t) + a_{2i+3} sen(a_{1} t)$, onde $a_i$ é a i-nésima constante do indivíduo. Tal função é uma série de Fourier truncada, boa para representar funções perióticas e fazer, portanto, cada articulação poder ser utilizada de forma independente em perídos diferentes serapadas das demais. Novamente escolhemos as articulações como alvo do aprendizado, pois, novamente, são elas que definem se o robô irá andar ou não.

A função fitness inicial que utilizamos foi bem simples: distância percorrida até o robô cair, sendo que cair é: centro de massa do robô ter girado mais de 90º em qualquer eixo, e parar de se deslocar por alguns instantes. Para isso, para cada indivíduo da população, executou-se uma simulação, utilizando os valores decodificados de seu cromossomo como as constantes da função de rotação citada. A cada intervalo de 0.01s todas as articulações tem seus angulos atualizados de acordo com sua respectiva função, e é verificado se o robo andou, caiu, ficou parado.

Nossos testes mostraram que depois de 10 gerações, todos os indivíduos praticamente já iam exclusivamente para frente, mesmo que caindo. Demonstrando que a população aprendeu que ir para trás não é o desejado. Entretanto ainda não fazia nenhum indicativo de passo de caminhada.

Então melhoramos a função fitness, colocando alguns cálculos a mais que indicam fazem uma caminhada algo melhor do que simplesmente cair. A ideia é reforçar movimentos que indicam que está caminhando com cabeça erguida, penalizando quedas ou ir, de alguma forma, para trás. Com esta função fitness melhorada, os resultados também foram melhores, mas ainda sim estavam longes de serem os desejados. O robô aprendeu a cair "lentamente" e para frente, o que, segundo a função fitness, dá um resultado melhor do que ficar parado, ou caior para os lados, e no chão até chega a dobrar as pernas, porém não adianta mais.

\section{Conclusões} \label{conclusoes}

Conclui-se que o problema de fazer um robô bípede é realmente complexa como esperávamos, e simular a natureza com estas técnias pode ser sim eficiente.

Após realizar as três abordagens, notamos em todas elas a necessidade de colocar o robô em uma posição inicial propícia para caminhar, e então executar as respectivas técnicas. Isso é algo aceitável, pois com o robô físico, pode-se colocá-lo nesta posição facilmente (joelhos e cotovelhos levemente flexionados, coluna levemente inclinada, braços para baixo), e no simulador, conseguimos deixá-lo assim com apenas 7 comandos de rotações nas devidas articulações. O ponto de partida foi fundamental para a abordagem de RNA, e ajudou bastante a de AG descobrir as devidas constantes da série de fourier truncada para cada junta mais rapidamente.

%******************************************************************************
% Referências - Definidas no arquivo Relatorio.bib
\nocite{Aula}
\bibliographystyle{IEEEtran}

\bibliography{Relatorio}

\end{document}
